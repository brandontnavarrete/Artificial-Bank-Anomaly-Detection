{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcf94f2",
   "metadata": {},
   "source": [
    "# dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643f92fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /usr/local/anaconda3/lib/python3.9/site-packages (18.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/anaconda3/lib/python3.9/site-packages (from faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9db2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: schedule in /usr/local/anaconda3/lib/python3.9/site-packages (1.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669eda2",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ce64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import schedule\n",
    "import time\n",
    "import signal\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a54b20",
   "metadata": {},
   "source": [
    "1. `csv`: This module provides functionality for reading and writing CSV (Comma-Separated Values) files. Although it's imported, it is not used in the code you provided.\n",
    "\n",
    "2. `pandas as pd`: Pandas is a powerful data manipulation library. It provides data structures and functions to efficiently manipulate and analyze structured data, such as CSV files. It is commonly imported as `pd` for convenience.\n",
    "\n",
    "3. `Faker`: Faker is a Python library that generates fake data for various purposes, such as testing and populating databases. It can generate fake names, addresses, phone numbers, and more. In the code, it is used to generate fake data for names, unique IDs, transactions, access times, and locations.\n",
    "\n",
    "4. `random`: The random module provides functions for generating random numbers and making random choices. In the code, it is used to generate random choices for transactions and to generate random time intervals for access times.\n",
    "\n",
    "5. `datetime, timedelta`: The `datetime` module provides classes for working with dates and times, and the `timedelta` class represents a duration or difference between two dates or times. In the code, they are used to generate random access times based on the current time.\n",
    "\n",
    "6. `schedule`: The schedule library provides a simple and intuitive way to schedule tasks to run at specific times. It allows you to schedule functions to run periodically or at specific intervals. In the code, it is used to schedule the `generate_and_update_data` function to run daily at 8:00 AM.\n",
    "\n",
    "7. `time`: The `time` module provides various time-related functions. In the code, it is used to introduce a small delay between iterations of the `while` loop to avoid excessive CPU usage.\n",
    "\n",
    "8. `signal`: The `signal` module provides mechanisms to handle signals raised by the operating system. In the code, it is used to define a signal handler for stopping the script gracefully when a specific signal is received.\n",
    "\n",
    "9. `sys`: The `sys` module provides access to some variables used or maintained by the interpreter and functions that interact with the interpreter. In the code, it is used to exit the script using `sys.exit()`.\n",
    "\n",
    "These imports bring in the necessary functionality to generate fake data, work with CSV files, schedule tasks, handle signals, and perform other necessary operations in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a5184",
   "metadata": {},
   "source": [
    "# End Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071cc8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for random number generation (to get consistent results)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc76e52",
   "metadata": {},
   "source": [
    "# Automated Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa92a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Faker object\n",
    "fake = Faker()\n",
    "\n",
    "# Generate fake data\n",
    "# Import the necessary modules\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define the range and mean for the transaction amount\n",
    "amount_range = (5000, -3000)\n",
    "amount_mean = -1000  # Adjust the mean as desired\n",
    "\n",
    "# Create a dictionary to store the unique IDs for each name\n",
    "name_ids = {}\n",
    "\n",
    "# Generate fake data\n",
    "def generate_fake_data(num_rows, existing_customers=[]):\n",
    "    data = []\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    for _ in range(num_rows):\n",
    "        # Determine if it's a new customer or an existing customer\n",
    "        if existing_customers and random.random() < 0.7:\n",
    "            # Select a random existing customer\n",
    "            name = random.choice(existing_customers)\n",
    "        else:\n",
    "            # Generate a fake name for a new customer\n",
    "            name = fake.name()\n",
    "            # Add the new customer to the existing customers list\n",
    "            existing_customers.append(name)\n",
    "\n",
    "        # Check if the name already has an ID assigned\n",
    "        if name in name_ids:\n",
    "            unique_id = name_ids[name]\n",
    "        else:\n",
    "            unique_id = fake.uuid4()\n",
    "            name_ids[name] = unique_id\n",
    "\n",
    "        # Generate a random transaction amount based on a normal distribution\n",
    "        amount = int(np.clip(random.normalvariate(amount_mean, 1000), amount_range[1], amount_range[0]))\n",
    "\n",
    "        transaction = \"withdraw\" if amount < 0 else \"deposit\"\n",
    "\n",
    "        access_time = current_time - timedelta(days=random.randint(0, 365), hours=random.randint(0, 23),\n",
    "                                               minutes=random.randint(0, 59))\n",
    "        location = fake.city()\n",
    "\n",
    "        data.append([name, unique_id, amount, transaction, access_time, location])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf5e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows you want in the dataframe\n",
    "num_rows = 15\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file = 'data.csv'\n",
    "\n",
    "# Define the maximum nuber of days to run the script\n",
    "max_days = 3\n",
    "\n",
    "# Variable to keep track of the number of days\n",
    "days_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb8f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and updte data\n",
    "\n",
    "def generate_and_update_data():\n",
    "    global days_count\n",
    "\n",
    "    # Generate the fake data\n",
    "    data = generate_fake_data(num_rows)\n",
    "\n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(data, columns=[\"Name\", \"ID\", 'amount' ,\"Transaction\", \"Access Time\", \"Location\"])\n",
    "\n",
    "    # Append the new data to the existing CSV file\n",
    "    df.to_csv(csv_file, mode='a', index=False, header=not csv_file_exists())\n",
    "\n",
    "    days_count += 1\n",
    "    print(\"Data updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943298e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The global days_count statement allows accessing and modifying the days_count variable defined outside the function.\n",
    "\n",
    "# data = generate_fake_data(num_rows) calls the generate_fake_data function to generate the fake data. The generated data is stored in the data variable.\n",
    "\n",
    "# df = pd.DataFrame(data, columns=[\"Name\", \"ID\", \"Transaction\", \"Access Time\", \"Location\"]) creates a pandas DataFrame using the generated data. The column names are specified as \"Name\", \"ID\", \"Transaction\", \"Access Time\", and \"Location\".\n",
    "\n",
    "# df.to_csv(csv_file, mode='a', index=False, header=not csv_file_exists()) appends the new data to the existing CSV file specified by csv_file. The mode='a' argument ensures the file is opened in append mode. The index=False argument avoids writing the row index to the CSV file. The header=not csv_file_exists() argument controls whether the header row is written to the file. If the CSV file already exists (csv_file_exists() returns True), the header row is not written.\n",
    "\n",
    "# days_count += 1 increments the days_count variable to keep track of the number of days the script has run.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1649c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CSV file exists\n",
    "def csv_file_exists():\n",
    "    try:\n",
    "        with open(csv_file, 'r') as file:\n",
    "            return True\n",
    "    except FileNotFoundError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6424fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try: starts a try-except block to catch any potential exceptions that may occur.\n",
    "\n",
    "# with open(csv_file, 'r') as file: opens the CSV file specified by csv_file in read mode. The with statement ensures that the file is properly closed after use.\n",
    "\n",
    "# return True is executed if the CSV file is successfully opened without raising any exceptions. This indicates that the file exists.\n",
    "\n",
    "# except FileNotFoundError: catches the FileNotFoundError exception, which is raised if the CSV file does not exist.\n",
    "\n",
    "# return False is executed if the FileNotFoundError exception is raised. This indicates that the file does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf3ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal handler to stop the script\n",
    "def stop_script(signal, frame):\n",
    "    print(\"Stopping the script...\")\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e190ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_data = generate_fake_data(num_rows) generates the initial fake data using the generate_fake_data function. The data is stored in the initial_data variable.\n",
    "\n",
    "# df_initial = pd.DataFrame(initial_data, columns=[\"Name\", \"ID\", \"Transaction\", \"Access Time\", \"Location\"]) creates a DataFrame (df_initial) from the initial data. The column names are specified as \"Name\", \"ID\", \"Transaction\", \"Access Time\", and \"Location\".\n",
    "\n",
    "# df_initial.to_csv(csv_file, mode='w', index=False) writes the initial data to the CSV file specified by csv_file. The mode='w' argument ensures that the file is opened in write mode. The index=False argument avoids writing the row index to the CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6817e14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 day at 10:00:00 do generate_and_update_data() (last run: [never], next run: 2023-05-20 10:00:00)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Schedule the task to run daily\n",
    "schedule.every().day.at(\"10:00\").do(generate_and_update_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f427013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schedule.every().day.at(\"08:00\").do(generate_and_update_data) schedules the generate_and_update_data function to run daily at 08:00. This is achieved using the schedule.every().day.at(\"08:00\") method chain, followed by .do(generate_and_update_data) to specify the function to be executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "936b4b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5dr5q0n145vcn3_m9dxy1xq80000gn/T/ipykernel_7916/271438853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mdays_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_days\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m360\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sleep for 6 hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the scheduled task continuously until the maximum number of days is reached\n",
    "while days_count < max_days:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(360 * 60)  # Sleep for 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a6a7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The while loop continuously runs the scheduled task until the days_count reaches the max_days. Within the loop, schedule.run_pending() checks if there are any pending tasks and runs them. time.sleep(1) pauses the execution for 1 second to avoid unnecessary CPU usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e16a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the script after the maximum number of days\n",
    "print(\"Maximum number of days reached. Stopping the script...\")\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673a4b1",
   "metadata": {},
   "source": [
    "# For Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d35b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to rapidly create some data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca09c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Define the range and mean for the transaction amount\n",
    "amount_range = (5000, -3000)\n",
    "amount_mean = -1000  # Adjust the mean as desired\n",
    "\n",
    "# Create a dictionary to store the unique IDs for each name\n",
    "name_ids = {}\n",
    "\n",
    "# Generate fake data\n",
    "def generate_fake_data(num_rows, existing_customers=[], repeating_customer_prob=0.7):\n",
    "    data = []\n",
    "    current_time = datetime.now()\n",
    "\n",
    "    for _ in range(num_rows):\n",
    "        # Determine if it's a new customer or an existing customer\n",
    "        if existing_customers and random.random() < repeating_customer_prob:\n",
    "            # Select a random existing customer\n",
    "            name = random.choice(existing_customers)\n",
    "        else:\n",
    "            # Generate a fake name for a new customer\n",
    "            name = fake.name()\n",
    "            # Add the new customer to the existing customers list\n",
    "            existing_customers.append(name)\n",
    "\n",
    "        # Check if the name already has an ID assigned\n",
    "        if name in name_ids:\n",
    "            unique_id = name_ids[name]\n",
    "        else:\n",
    "            unique_id = fake.uuid4()\n",
    "            name_ids[name] = unique_id\n",
    "\n",
    "        # Generate a random transaction amount based on a normal distribution\n",
    "        amount = int(np.clip(random.normalvariate(amount_mean, 1000), amount_range[1], amount_range[0]))\n",
    "\n",
    "        transaction = \"withdraw\" if amount < 0 else \"deposit\"\n",
    "\n",
    "        access_time = current_time - timedelta(days=random.randint(0, 365), hours=random.randint(0, 23),\n",
    "                                               minutes=random.randint(0, 59))\n",
    "        location = fake.city()\n",
    "\n",
    "        data.append([name, unique_id, amount, transaction, access_time, location])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "686a57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of rows you want in the dataframe\n",
    "num_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5860809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and append initial data\n",
    "# initial_data = generate_fake_data(num_rows)\n",
    "# df_initial = pd.DataFrame(initial_data, columns=[\"Name\", \"ID\", 'amount',\"Transaction\", \"Access Time\", \"Location\"])\n",
    "# df_initial.to_csv(csv_file, mode='w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1f10532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(100):\n",
    "    df = pd.DataFrame(generate_fake_data(num_rows))  # Assuming you have a function generate_fake_data() that generates fake data\n",
    "    \n",
    "    data = pd.concat([data, df])  # Concatenate the generated DataFrame to the existing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b0dcbef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.rename( columns= {0: 'name',\n",
    "                       1: 'id',\n",
    "                       2: 'amount',\n",
    "                       3: 'transaction',\n",
    "                       4: 'access_time',\n",
    "                       5: 'town'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc03c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed8a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
